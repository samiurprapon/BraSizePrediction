{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast classification and Bra Size prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image datas with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(img_path, flag):\n",
    "    filename, extension = os.path.splitext(os.path.basename(img_path))\n",
    "    \n",
    "    subject_id, etc = filename.split(\"__\") # 2 underscore\n",
    "    bra = 0\n",
    "    \n",
    "    if flag:\n",
    "        breast_size, waist_size, band_size, cup_size, with_bra = etc.split('_')        \n",
    "\n",
    "        if with_bra == 'true':\n",
    "            bra = 1\n",
    "        else:\n",
    "            bra = 0\n",
    "\n",
    "        return np.array([subject_id, breast_size, waist_size, band_size, cup_size, bra])\n",
    "    else:\n",
    "        breast_size, waist_size, band_size, cup_size = etc.split('_')\n",
    "        return np.array([subject_id, breast_size, waist_size, band_size, cup_size, bra])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bra_path = \"./dataset/with_bra\"\n",
    "without_bra_path = \"./dataset/without_bra\"\n",
    "\n",
    "img_size = 192\n",
    "\n",
    "with_bra_data = []\n",
    "with_out_bra_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without bra\n",
    "for image in os.listdir(without_bra_path):\n",
    "    img = cv2.imread(os.path.join(without_bra_path, image), cv2.IMREAD_COLOR)\n",
    "        \n",
    "    # flag = 0 -> no bra\n",
    "    # flag = 1 -> has bra\n",
    "    label = extract_label(os.path.join(without_bra_path, image), False)\n",
    "\n",
    "    with_out_bra_data.append([label[0], label[1], label[2], label[3], label[4], label[5], img])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with bra\n",
    "for image in os.listdir(bra_path):\n",
    "    img = cv2.imread(os.path.join(bra_path, image), cv2.IMREAD_COLOR)\n",
    "        \n",
    "    label = extract_label(os.path.join(bra_path, image), True)\n",
    "    \n",
    "    # flag = 0 -> no bra\n",
    "    # flag = 1 -> has bra\n",
    "    with_bra_data.append([label[0], label[1], label[2], label[3], label[4], label[5], img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image arry to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_with_bra_data= np.array(with_bra_data, dtype=\"object\")\n",
    "np_with_out_bra_data = np.array(with_out_bra_data, dtype=\"object\")\n",
    "\n",
    "#concatenating through column(axis = 0)\n",
    "np_data = np.concatenate((np_with_bra_data, np_with__out_bra_data), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 7)\n"
     ]
    }
   ],
   "source": [
    "print(np_with_bra_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 7)\n"
     ]
    }
   ],
   "source": [
    "print(np_with_out_bra_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 7)\n"
     ]
    }
   ],
   "source": [
    "print(np_data.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert numpy array to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_dani_daniels</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0, 220, 188], [6, 221, 190], [15, 212, 186]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_eva_elfie</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>cc</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[253, 253, 253], [253, 253, 253], [253, 253,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0   1   2   3   4  5  \\\n",
       "0  10_dani_daniels  34  24  34   d  1   \n",
       "1     10_eva_elfie  36  26  34  cc  1   \n",
       "\n",
       "                                                   6  \n",
       "0  [[[0, 220, 188], [6, 221, 190], [15, 212, 186]...  \n",
       "1  [[[253, 253, 253], [253, 253, 253], [253, 253,...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[5].values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(dataframe[6][400])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6a7cb9e924d6de1de40c129b310dac65a7dcf305c3982e51303baf3b09b890b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
