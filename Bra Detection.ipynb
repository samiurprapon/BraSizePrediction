{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bra detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img , img_to_array\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(img_path, flag):\n",
    "    filename, extension = os.path.splitext(os.path.basename(img_path))\n",
    "    \n",
    "    subject_id, etc = filename.split(\"__\") # 2 underscore\n",
    "    bra = 0\n",
    "    \n",
    "    if flag:\n",
    "        breast_size, waist_size, band_size, cup_size, with_bra = etc.split('_')        \n",
    "\n",
    "        if with_bra == 'true':\n",
    "            bra = 1\n",
    "        else:\n",
    "            bra = 0\n",
    "\n",
    "        return bra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bra_path = \"./dataset/with_bra\"\n",
    "without_bra_path = \"./dataset/without_bra\"\n",
    "\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(without_bra_path):\n",
    "    img = cv2.imread(os.path.join(without_bra_path, image), cv2.IMREAD_COLOR)\n",
    "        \n",
    "    # flag = 0 -> no bra\n",
    "    # flag = 1 -> has bra\n",
    "    label = extract_label(os.path.join(without_bra_path, image), False)\n",
    "    \n",
    "    labels.append(label)\n",
    "    images.append(img);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(without_bra_path):\n",
    "    img = cv2.imread(os.path.join(without_bra_path, image), cv2.IMREAD_COLOR)\n",
    "        \n",
    "    # flag = 0 -> no bra\n",
    "    # flag = 1 -> has bra\n",
    "    label = extract_label(os.path.join(without_bra_path, image), False)\n",
    "    \n",
    "    labels.append(label)\n",
    "    images.append(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image arry to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = np.array(images, dtype=\"object\")\n",
    "np_labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2 acrchitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(512,(2,2),padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D((2,2),strides=2))\n",
    "\n",
    "model.add(Conv2D(256,(2,2),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2),strides=2))\n",
    "\n",
    "model.add(Conv2D(128,(2,2),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2),strides=2))\n",
    "\n",
    "model.add(Conv2D(64,(2,2),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2),strides=2))\n",
    "\n",
    "model.add(Conv2D(32,(2,2),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2),strides=2))\n",
    "\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model.fit(img_gen.flow(X_train,y_train,batch_size=5),\n",
    "                    steps_per_epoch=300,\n",
    "                    validation_data=(X_test,y_test),\n",
    "                    validation_steps=300,\n",
    "                    epochs=45)\n",
    "end = time.time()\n",
    "print(\"Total train time: \",(end-start)/60,\" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(history,string):\n",
    "    plt.figure(figsize=(16,7))\n",
    "    plt.plot(history.history[string],label=str(string))\n",
    "    plt.plot(history.history[\"val_\"+str(string)],label=str(string))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string,\"val_\"+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history,\"accuracy\")\n",
    "plot_graph(history,\"loss\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6a7cb9e924d6de1de40c129b310dac65a7dcf305c3982e51303baf3b09b890b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
